{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os, sys\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from model import ROD_cluster\n",
    "from optimizer import loss_function\n",
    "from utils import *\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from clustering_metric import clustering_metrics\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cora dataset\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--epochs', type=int, default=200)\n",
    "parser.add_argument('--num_hops', type=int, default=3)\n",
    "parser.add_argument('--dims', type=int, default=[64])\n",
    "parser.add_argument('--lr', type=float, default=1e-2)\n",
    "parser.add_argument('--batch_size', type=int, default=1000)\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4)\n",
    "parser.add_argument('--upd', type=int, default=10)\n",
    "parser.add_argument('--dataset', type=str, default='cora')\n",
    "parser.add_argument('--device', type=int, default=0)\n",
    "args = parser.parse_args(args=[])\n",
    "print(\"Using {} dataset\".format(args.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == 'cora':\n",
    "    n_clusters = 7\n",
    "    lr = 1e-2\n",
    "    start_hops = 4\n",
    "elif args.dataset == 'citeseer':\n",
    "    n_clusters = 6\n",
    "    lr = 1e-3\n",
    "    start_hops = 3\n",
    "elif args.dataset == 'pubmed':\n",
    "    n_clusters = 3\n",
    "    lr = 1e-3\n",
    "    start_hops = 15\n",
    "\n",
    "device = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")\n",
    "adj, features, true_labels, idx_train, idx_val, idx_test = load_data(args.dataset)\n",
    "n_nodes, feat_dim = features.shape\n",
    "dims = [feat_dim] + args.dims\n",
    "\n",
    "adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
    "adj.eliminate_zeros()\n",
    "\n",
    "n = adj.shape[0]\n",
    "\n",
    "adj_normalized = preprocess_graph(adj, norm='sym', renorm=True)\n",
    "features = sp.csr_matrix(features).toarray()\n",
    "\n",
    "for i in range(start_hops):\n",
    "    features = adj_normalized.dot(features)\n",
    "\n",
    "feature_list = [features]\n",
    "for i in range(args.num_hops):\n",
    "    feature_list.append(adj_normalized.dot(feature_list[-1]))\n",
    "input_feature = [torch.FloatTensor(feat).to(device) for feat in feature_list]\n",
    "\n",
    "adj_1st = (adj + sp.eye(n)).toarray()\n",
    "adj_label = torch.FloatTensor(adj_1st)\n",
    "neg_num = pos_num = adj_label.sum().long()\n",
    "\n",
    "model = ROD_cluster(dims, n_clusters, args.num_hops)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_sim_mx_list = []\n",
    "for i in range(args.num_hops+1):\n",
    "    cur_feat = F.normalize(input_feature[i].cpu().data)\n",
    "    sm_sim_mx_list.append(torch.mm(cur_feat, cur_feat.t()).reshape([-1,]))\n",
    "\n",
    "adj_label = adj_label.reshape([-1,])\n",
    "model = model.to(device)\n",
    "\n",
    "pos_inds_list = []\n",
    "neg_inds_list = []\n",
    "for i in range(args.num_hops+1):\n",
    "    pos_inds_list.append(np.argpartition(-sm_sim_mx_list[i], pos_num)[:pos_num])\n",
    "    neg_inds_list.append(np.argpartition(sm_sim_mx_list[i], pos_num*200)[:pos_num*200])\n",
    "\n",
    "length = len(pos_inds_list[0])\n",
    "length_neg = len(neg_inds_list[0])\n",
    "\n",
    "pos_inds_cuda_list = [torch.LongTensor(pos_inds).to(device) for pos_inds in pos_inds_list]\n",
    "\n",
    "batch_size = args.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:01<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Finished!\n",
      "best_acc: 0.7381831610044313, best_nmi: 0.5647414596533694, best_adj: 0.51282299584066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kmeans_list = [KMeans(n_clusters=n_clusters, n_init=20)]\n",
    "for _ in range(args.num_hops+1):\n",
    "    kmeans_list.append(KMeans(n_clusters=n_clusters, n_init=20))\n",
    "\n",
    "tqdm.write('Start Training...')\n",
    "for epoch in tqdm(range(args.epochs)):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    z_list = model(input_feature)\n",
    "    start, end = 0, batch_size\n",
    "    loss1 = 0.\n",
    "    ran_head = np.random.randint(0, length_neg-length-1)\n",
    "    sampled_neg_list = []\n",
    "    for i in range(args.num_hops+1):\n",
    "        sampled_neg_list.append(torch.LongTensor(neg_inds_list[i][np.arange(ran_head, ran_head+length)]).to(device))\n",
    "\n",
    "    if epoch % args.upd == 0:\n",
    "        label_list = []\n",
    "        centroid_list = []\n",
    "        for i in range(args.num_hops+1):\n",
    "            label_list.append(kmeans_list[i].fit_predict(z_list[i].data.cpu().numpy()))\n",
    "            centroid_list.append(kmeans_list[i].cluster_centers_)\n",
    "\n",
    "        new_label_list = [label_list[0]]\n",
    "        new_centroid_list = [torch.FloatTensor(centroid_list[0]).to(device)]\n",
    "\n",
    "        for i in range(1, args.num_hops+1):\n",
    "            temp_label, temp_index = munkres(label_list[i], label_list[0])\n",
    "            temp_centroid = np.array([centroid_list[i][temp_index[j][1]] for j in range(n_clusters)])\n",
    "            new_label_list.append(temp_label)\n",
    "            new_centroid_list.append(torch.FloatTensor(temp_centroid).to(device))\n",
    "\n",
    "    dist_list = []\n",
    "    for i in range(args.num_hops+1):\n",
    "        for j in range(n_clusters):\n",
    "            if j == 0:\n",
    "                dist = torch.norm(z_list[i] - new_centroid_list[i][j], p=2, dim=1, keepdim=True)\n",
    "            else:\n",
    "                dist = torch.cat((dist, torch.norm(z_list[i] - new_centroid_list[i][j], p=2, dim=1, keepdim=True)), 1)\n",
    "        dist_list.append(dist)\n",
    "\n",
    "    dist_norm_list = [F.softmax(dist, 1) for dist in dist_list]\n",
    "\n",
    "    attention_scores = [torch.sigmoid(model.lr_att2(dist_norm)).view(n_nodes, 1) for dist_norm in dist_norm_list]\n",
    "    W = torch.cat(attention_scores, dim=1)\n",
    "    W = F.softmax(W, 1)\n",
    "\n",
    "    dist_ensemble = torch.mul(dist_norm_list[0], W[:, 0].view(n_nodes, 1))\n",
    "    for i in range(1, args.num_hops+1):\n",
    "        dist_ensemble += torch.mul(dist_norm_list[i], W[:, i].view(n_nodes, 1))\n",
    "\n",
    "    label_ensemble = dist_ensemble.min(1)[1].long().cpu().numpy()\n",
    "    if len(list(set(label_ensemble))) < n_clusters:\n",
    "        y_pred = kmeans_list[args.num_hops+1].fit_predict(dist_ensemble.data.cpu().numpy())\n",
    "    else:\n",
    "        y_pred = label_ensemble\n",
    "\n",
    "    if epoch == 0:\n",
    "        cm = clustering_metrics(true_labels, y_pred)\n",
    "        best_acc, best_nmi, best_ari = cm.evaluationClusterModelFromLabel(tqdm)\n",
    "    else:\n",
    "        cm = clustering_metrics(true_labels, y_pred)\n",
    "        acc, nmi, ari = cm.evaluationClusterModelFromLabel(tqdm)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_nmi = nmi\n",
    "            best_ari = ari\n",
    "\n",
    "    loss3 = 0.\n",
    "    for i in range(args.num_hops+1):\n",
    "        loss3 += F.mse_loss(dist_norm_list[i], dist_ensemble)\n",
    "\n",
    "    loss2 = 0.\n",
    "    for i in range(args.num_hops+1):\n",
    "        loss_tmp = -dist_list[i].mean(1).sum()\n",
    "        # loss_tmp += 2 * np.sum([dist_list[i].cpu()[j, x] for j, x in zip(range(dist_list[i].shape[0]), new_label_list[i])])\n",
    "        loss_tmp += 2 * torch.sum(torch.stack([dist_list[i][j, x] for j, x in zip(range(dist_list[i].shape[0]), new_label_list[i])]))\n",
    "        loss2 += loss_tmp / n_nodes\n",
    "\n",
    "    while end <= length:\n",
    "        for i in range(args.num_hops+1):\n",
    "            sampled_inds = torch.cat((pos_inds_cuda_list[i][start:end], sampled_neg_list[i][start:end]), 0)\n",
    "            xind = sampled_inds // n_nodes\n",
    "            yind = sampled_inds % n_nodes\n",
    "            zx = torch.index_select(z_list[i], 0, xind)\n",
    "            zy = torch.index_select(z_list[i], 0, yind)\n",
    "            batch_label = torch.cat((torch.ones(end-start), torch.zeros(end-start))).to(device)\n",
    "            batch_pred = (zx * zy).sum(1)\n",
    "            weight = torch.cat((batch_pred[:batch_size], 1-batch_pred[batch_size:]), 0).data\n",
    "            loss1 += loss_function(adj_preds=batch_pred, adj_labels=batch_label, weight=weight)\n",
    "\n",
    "        start = end\n",
    "        if end < length <= end + batch_size:\n",
    "            end += length - end\n",
    "        else:\n",
    "            end += batch_size\n",
    "\n",
    "    loss = 1*loss1 + 10*loss2 + 10*loss3\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "tqdm.write(\"Optimization Finished!\")\n",
    "tqdm.write('best_acc: {}, best_nmi: {}, best_adj: {}'.format(best_acc, best_nmi, best_ari))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
