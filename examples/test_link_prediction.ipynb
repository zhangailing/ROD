{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os, sys\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "\n",
    "SEED = 4\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from model import ROD_lp\n",
    "from optimizer import loss_function\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cora dataset\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--num_hops', type=int, default=5)\n",
    "parser.add_argument('--epochs', type=int, default=400)\n",
    "parser.add_argument('--dims', type=int, default=[1024])\n",
    "parser.add_argument('--lr', type=float, default=0.001)\n",
    "parser.add_argument('--batch_size', type=int, default=500)\n",
    "parser.add_argument('--dataset', type=str, default='cora')\n",
    "parser.add_argument('--device', type=int, default=0)\n",
    "parser.add_argument('--upd', type=int, default=10)\n",
    "args = parser.parse_args(args=[])\n",
    "print(\"Using {} dataset\".format(args.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")\n",
    "adj, features, true_labels, idx_train, idx_val, idx_test = load_data(args.dataset)\n",
    "n_nodes, feat_dim = features.shape\n",
    "dims = [feat_dim] + args.dims\n",
    "\n",
    "adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
    "adj.eliminate_zeros()\n",
    "adj_orig = adj\n",
    "\n",
    "adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
    "adj = adj_train\n",
    "n = adj.shape[0]\n",
    "\n",
    "adj_normalized = preprocess_graph(adj, norm='sym', renorm=True)\n",
    "features = sp.csr_matrix(features).toarray()\n",
    "    \n",
    "feature_list = [features]\n",
    "for i in range(args.num_hops):\n",
    "    feature_list.append(adj_normalized.dot(feature_list[-1]))\n",
    "input_feature = [torch.FloatTensor(feat).to(device) for feat in feature_list] \n",
    "\n",
    "adj_1st = (adj + sp.eye(n)).toarray()\n",
    "\n",
    "adj_label = torch.FloatTensor(adj_1st)\n",
    "\n",
    "neg_num = pos_num = adj_label.sum().long()\n",
    "\n",
    "model = ROD_lp(dims, args.num_hops)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_sim_mx_list = []\n",
    "for i in range(args.num_hops+1):\n",
    "    cur_feat = F.normalize(input_feature[i].cpu().data)\n",
    "    sm_sim_mx_list.append(torch.mm(cur_feat, cur_feat.t()).reshape([-1,]))\n",
    "\n",
    "adj_label = adj_label.reshape([-1, ])\n",
    "\n",
    "model = model.to(device)\n",
    "adj_label = adj_label.to(device)\n",
    "\n",
    "pos_inds_list = []\n",
    "neg_inds_list = []\n",
    "for i in range(args.num_hops+1):\n",
    "    pos_inds_list.append(np.argpartition(-sm_sim_mx_list[i], pos_num)[:pos_num])\n",
    "    neg_inds_list.append(np.argpartition(sm_sim_mx_list[i], pos_num*200)[:pos_num*200])\n",
    "\n",
    "pos_inds_ensemble = np.concatenate(pos_inds_list, axis=0)\n",
    "neg_inds_ensemble = np.concatenate(neg_inds_list, axis=0)\n",
    "    \n",
    "length_ensemble = len(pos_inds_ensemble)\n",
    "length_ensemble_neg = len(neg_inds_ensemble)\n",
    "    \n",
    "length = len(pos_inds_list[0])\n",
    "length_neg = len(neg_inds_list[0])\n",
    "\n",
    "pos_inds_ensemble_cuda = torch.LongTensor(pos_inds_ensemble).to(device)\n",
    "pos_inds_cuda_list = [torch.LongTensor(pos_inds).to(device) for pos_inds in pos_inds_list]\n",
    "\n",
    "batch_size = args.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 10/400 [00:09<06:01,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, train_loss_gae=265.56262, time=1.17799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 20/400 [00:17<05:46,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, train_loss_gae=259.73642, time=1.16615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 30/400 [00:26<05:56,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, train_loss_gae=255.40619, time=1.24016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 40/400 [00:34<05:32,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, train_loss_gae=251.52681, time=1.18879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 50/400 [00:43<05:24,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, train_loss_gae=249.87376, time=1.17592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 60/400 [00:51<05:12,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60, train_loss_gae=245.72154, time=1.20336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 70/400 [01:00<05:09,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70, train_loss_gae=243.93951, time=1.18776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 80/400 [01:08<04:50,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80, train_loss_gae=242.54346, time=1.17101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 90/400 [01:16<04:41,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90, train_loss_gae=241.48589, time=1.15625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 100/400 [01:25<04:30,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, train_loss_gae=239.85323, time=1.16544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 110/400 [01:33<04:22,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110, train_loss_gae=238.25244, time=1.15104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 120/400 [01:41<04:12,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120, train_loss_gae=237.89786, time=1.15018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 130/400 [01:49<04:10,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130, train_loss_gae=235.63214, time=1.23590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 140/400 [01:58<03:54,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140, train_loss_gae=234.91306, time=1.14559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 150/400 [02:06<03:47,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150, train_loss_gae=234.75591, time=1.17282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 160/400 [02:14<03:37,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160, train_loss_gae=235.47620, time=1.15709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 170/400 [02:23<03:31,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170, train_loss_gae=233.50177, time=1.17283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 180/400 [02:31<03:24,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180, train_loss_gae=233.52017, time=1.21372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 190/400 [02:40<03:12,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 190, train_loss_gae=231.84271, time=1.17852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 200/400 [02:48<03:02,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200, train_loss_gae=231.12776, time=1.17088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 210/400 [02:56<02:55,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 210, train_loss_gae=229.98880, time=1.19796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 220/400 [03:05<02:44,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220, train_loss_gae=230.51297, time=1.16934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 230/400 [03:13<02:36,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 230, train_loss_gae=229.94714, time=1.18920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 240/400 [03:22<02:31,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 240, train_loss_gae=229.67207, time=1.20962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 250/400 [03:31<02:45,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250, train_loss_gae=230.17270, time=1.54185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 260/400 [03:41<02:26,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 260, train_loss_gae=229.61797, time=1.41976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 270/400 [03:50<02:13,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 270, train_loss_gae=228.34282, time=1.38383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 280/400 [03:59<02:08,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 280, train_loss_gae=229.61380, time=1.45446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 290/400 [04:08<01:46,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 290, train_loss_gae=227.68752, time=1.19056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 300/400 [04:17<01:39,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300, train_loss_gae=226.75423, time=1.22768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 310/400 [04:26<01:28,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 310, train_loss_gae=226.07558, time=1.20234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 320/400 [04:36<01:29,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 320, train_loss_gae=227.29707, time=1.49906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 330/400 [04:47<01:19,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 330, train_loss_gae=227.79396, time=1.49225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 340/400 [04:56<01:03,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 340, train_loss_gae=226.47716, time=1.41819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 350/400 [05:06<00:53,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350, train_loss_gae=225.37592, time=1.43759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 360/400 [05:16<00:44,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360, train_loss_gae=226.34306, time=1.38019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 370/400 [05:26<00:32,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 370, train_loss_gae=227.52266, time=1.44697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 380/400 [05:35<00:21,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 380, train_loss_gae=226.24983, time=1.45776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 390/400 [05:45<00:10,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 390, train_loss_gae=225.49178, time=1.25663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [05:54<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400, train_loss_gae=225.49290, time=1.39334\n",
      "Optimization Finished!\n",
      "Test AUC score: 0.9593848679828179\n",
      "Test AP score: 0.9624760908405264\n"
     ]
    }
   ],
   "source": [
    "best_lp = 0.\n",
    "best_emb_list = []\n",
    "tqdm.write('Start Training...')\n",
    "for epoch in tqdm(range(args.epochs)):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    all_time_per_epoch = 0.\n",
    "    t = time.time()\n",
    "    z_list = model(input_feature)\n",
    "\n",
    "    start, end = 0, batch_size\n",
    "    start_ensemble, end_ensemble = 0, batch_size*args.num_hops\n",
    "    batch_num = 0\n",
    "    loss = 0.\n",
    "\n",
    "    ran_head = np.random.randint(0, length_neg - length - 1)\n",
    "    sampled_neg_list = []\n",
    "    for i in range(args.num_hops+1):\n",
    "        sampled_neg_list.append(torch.LongTensor(neg_inds_list[i][np.arange(ran_head, ran_head+length)]).to(device))\n",
    "   \n",
    "    ran_head_0 = np.random.randint(0, length_ensemble_neg - length_ensemble - 1)\n",
    "    sample_neg_ensemble = torch.LongTensor(neg_inds_ensemble[np.arange(ran_head_0, ran_head_0+length_ensemble)]).cuda()\n",
    "\n",
    "    while end_ensemble <= length_ensemble:\n",
    "        sample_ensemble_inds = torch.cat((pos_inds_ensemble_cuda[start_ensemble:end_ensemble], sample_neg_ensemble[start_ensemble:end_ensemble]), 0)\n",
    "        sample_ensemble_inds = sample_ensemble_inds.cuda()\n",
    "        xind = sample_ensemble_inds // n_nodes\n",
    "        yind = sample_ensemble_inds % n_nodes\n",
    "        batch_label_original = torch.index_select(adj_label, 0, sample_ensemble_inds)\n",
    "\n",
    "        batch_pred_ensemble_list = []\n",
    "        for i in range(args.num_hops+1):\n",
    "            sampled_inds = torch.cat((pos_inds_cuda_list[i][start:end], sampled_neg_list[i][start:end]), 0).to(device)\n",
    "            xind = sampled_inds // n_nodes\n",
    "            yind = sampled_inds % n_nodes\n",
    "            zx_ensemble = torch.index_select(z_list[i], 0, xind)\n",
    "            zy_ensemble = torch.index_select(z_list[i], 0, yind)\n",
    "            zx = torch.index_select(z_list[i], 0, xind)\n",
    "            zy = torch.index_select(z_list[i], 0, yind)\n",
    "            batch_label = torch.cat((torch.ones(end-start), torch.zeros(end-start))).to(device)\n",
    "            batch_label_original = torch.index_select(adj_label, 0, sampled_inds)\n",
    "            batch_pred = (zx * zy).sum(1)\n",
    "            batch_pred_ensemble = (zx_ensemble * zy_ensemble).sum(1)\n",
    "            batch_pred_ensemble_list.append(batch_pred_ensemble)\n",
    "            weight = torch.cat((batch_pred[:batch_size], 1-batch_pred[batch_size:]), 0).data\n",
    "            loss += loss_function(adj_preds=batch_pred, adj_labels=batch_label_original)\n",
    "            sm_sim_mx = sm_sim_mx_list[i].to(device)\n",
    "            batch_label_soft = torch.index_select(sm_sim_mx, 0, sampled_inds)\n",
    "            loss += 0.2*loss_function(adj_preds=batch_pred, adj_labels=batch_label, weight=weight)\n",
    "            loss += 0.2*F.mse_loss(batch_pred, batch_label_soft)\n",
    "        \n",
    "        attention_scores = [torch.sigmoid(model.lr_att2(batch_pred.view(-1,1))).view(batch_pred.shape[0], 1) for batch_pred in batch_pred_ensemble_list]\n",
    "        W = torch.cat(attention_scores, dim=1)\n",
    "        W = F.softmax(W, 1)\n",
    "\n",
    "        pred_ensemble = torch.mul(batch_pred_ensemble_list[0], W[:, 0])\n",
    "        for i in range(1, args.num_hops+1):\n",
    "            pred_ensemble += torch.mul(batch_pred_ensemble_list[i], W[:, i])\n",
    "\n",
    "        #teacher loss\n",
    "        for i in range(args.num_hops+1):\n",
    "            loss += 0.1*F.kl_div(F.log_softmax(batch_pred_ensemble_list[i], dim=-1), F.softmax(pred_ensemble, dim=-1), reduction='mean')\n",
    "            loss += 0.1*loss_function(adj_preds=batch_pred_ensemble_list[i], adj_labels=pred_ensemble)\n",
    "            loss += loss_function(adj_preds=batch_pred_ensemble_list[i], adj_labels=batch_label_original)\n",
    "     \n",
    "        start_ensemble = end_ensemble\n",
    "        start = end\n",
    "        if end_ensemble < length_ensemble <= end_ensemble + (args.num_hops+1)*batch_size:\n",
    "            break\n",
    "        else:\n",
    "            end += batch_size\n",
    "            end_ensemble += (args.num_hops+1)*batch_size\n",
    "        \n",
    "    loss.backward()\n",
    "    cur_loss = loss.item()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % args.upd == 0:\n",
    "        model.eval()\n",
    "        z_list = model(input_feature)\n",
    "        z_list = [zz.cpu().data.numpy() for zz in z_list]\n",
    "    \n",
    "        val_auc, val_ap = get_roc_score_ensemble(z_list, adj_orig, val_edges, val_edges_false)\n",
    "        if val_auc + val_ap >= best_lp:\n",
    "            best_lp = val_auc + val_ap\n",
    "            best_emb_list = [z_list[0]]\n",
    "            for i in range(1, len(z_list)):\n",
    "                best_emb_list.append(z_list[i])\n",
    "        tqdm.write(\"Epoch: {}, train_loss_gae={:.5f}, time={:.5f}\".format(\n",
    "            epoch + 1, cur_loss, time.time() - t))\n",
    "\n",
    "tqdm.write(\"Optimization Finished!\")\n",
    "auc_score, ap_score = get_roc_score_ensemble(best_emb_list, adj_orig, test_edges, test_edges_false)\n",
    "tqdm.write('Test AUC score: ' + str(auc_score))\n",
    "tqdm.write('Test AP score: ' + str(ap_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
